{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4194617a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tweets BERT\n",
    "\n",
    "Adapted from [here](https://www.kaggle.com/brendanartley/roberta-w-tensorflow-explained-0-844/notebook). Compared to the kaggle author, we have:\n",
    "1. updated the HEAD to have a configurable MLP\n",
    "1. added regularization\n",
    "1. made the pipeline configurable\n",
    "1. performed small hyperparameter search (a dozen of configurations, searched by hand and without cross validation due to lack of computing resources)\n",
    "1. implemented best model evaluation metrics\n",
    "1. log the best checkpoint according to validation loss\n",
    "1. trained the best model on the whole dataset to make it ready for production (production for us is quotebank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6f8af4b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 03:01:57.106165: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n",
      "/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: mpi4py.MPI.Status size changed, may indicate binary incompatibility. Expected 40 from C header, got 48 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: mpi4py.MPI.Datatype size changed, may indicate binary incompatibility. Expected 24 from C header, got 32 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: mpi4py.MPI.Request size changed, may indicate binary incompatibility. Expected 32 from C header, got 40 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: mpi4py.MPI.Prequest size changed, may indicate binary incompatibility. Expected 32 from C header, got 40 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: mpi4py.MPI.Grequest size changed, may indicate binary incompatibility. Expected 40 from C header, got 48 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: mpi4py.MPI.Message size changed, may indicate binary incompatibility. Expected 32 from C header, got 40 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: mpi4py.MPI.Op size changed, may indicate binary incompatibility. Expected 40 from C header, got 48 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: mpi4py.MPI.Group size changed, may indicate binary incompatibility. Expected 24 from C header, got 32 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: mpi4py.MPI.Info size changed, may indicate binary incompatibility. Expected 24 from C header, got 32 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: mpi4py.MPI.Errhandler size changed, may indicate binary incompatibility. Expected 24 from C header, got 32 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: mpi4py.MPI.Comm size changed, may indicate binary incompatibility. Expected 24 from C header, got 32 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: mpi4py.MPI.Intracomm size changed, may indicate binary incompatibility. Expected 24 from C header, got 32 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: mpi4py.MPI.Topocomm size changed, may indicate binary incompatibility. Expected 24 from C header, got 32 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: mpi4py.MPI.Cartcomm size changed, may indicate binary incompatibility. Expected 24 from C header, got 32 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: mpi4py.MPI.Graphcomm size changed, may indicate binary incompatibility. Expected 24 from C header, got 32 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: mpi4py.MPI.Distgraphcomm size changed, may indicate binary incompatibility. Expected 24 from C header, got 32 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: mpi4py.MPI.Intercomm size changed, may indicate binary incompatibility. Expected 24 from C header, got 32 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: mpi4py.MPI.Win size changed, may indicate binary incompatibility. Expected 32 from C header, got 40 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: mpi4py.MPI.File size changed, may indicate binary incompatibility. Expected 32 from C header, got 40 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow_hub as hub\n",
    "import h5py\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py\n",
    "import tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f11a8d2",
   "metadata": {},
   "source": [
    "## <center>NLP Disaster Tweet Classification w/ roBERTa</center>\n",
    "\n",
    "This notebook implements a roBERTa model in Tensorflow to evaluate whether a tweet is about a disaster or not. I have provided explanations throughout to provide a better understanding of what the roBERTa model is actually doing.\n",
    "\n",
    "I got most of my understanding for this notebook from a good discussion thread about the roBERTa model from @Chris Deotte explaining how the components of the model work and his starter notebook on the roBERTa model. These are the top two links below. I also found the Tensorflow documentation quite informative as well (third and fourth links).\n",
    "\n",
    "### Useful Links\n",
    "\n",
    "This is a collection of links that I found helpful in understanding the structure of the roBERTa model, how it works, and more.\n",
    "\n",
    "- [TensorFlow roBERTa Explained Discussion](https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/143281#807401)\n",
    "- [tensorflow-roberta-0-705 Notebook](https://www.kaggle.com/cdeotte/tensorflow-roberta-0-705)\n",
    "- [Bert_en_uncased Docs](https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4)\n",
    "- [bert_en_uncased_preprocess](https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3)\n",
    "- [How to get meaning from text with language model BERT](https://www.youtube.com/watch?v=-9vVhYEXeyQ)\n",
    "- [TF Bert Tokenizer](https://github.com/google-research/bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f48472c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T04:29:56.637438Z",
     "iopub.status.busy": "2021-11-22T04:29:56.636643Z",
     "iopub.status.idle": "2021-11-22T04:29:56.639421Z",
     "shell.execute_reply": "2021-11-22T04:29:56.638952Z",
     "shell.execute_reply.started": "2021-11-22T04:24:01.325633Z"
    },
    "papermill": {
     "duration": 0.018742,
     "end_time": "2021-11-22T04:29:56.639536",
     "exception": false,
     "start_time": "2021-11-22T04:29:56.620794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FINAL_TRAIN = True # True for production. Will train the model on all available data (train+test)\n",
    "\n",
    "TWEETS_DATASET_PATH = \"../datasets/disaster-tweets\"\n",
    "SEED = 72\n",
    "MAX_LEN = 300\n",
    "LEARNING_RATE = 5e-6\n",
    "N_HIDDEN_UNITS = \"1024,512,256\" # The head we will use\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 8\n",
    "L2_LOSS_CONST = 3e-3\n",
    "MODEL_CHECKPOINT_NAME = f\"model_lr={LEARNING_RATE}_hid={N_HIDDEN_UNITS}_maxlen={MAX_LEN}_batch={BATCH_SIZE}_epochs={EPOCHS}_seed={SEED}_l2={L2_LOSS_CONST}.h5\"\n",
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed) \n",
    "    \n",
    "seed_everything(SEED) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bef3d26",
   "metadata": {
    "papermill": {
     "duration": 0.011318,
     "end_time": "2021-11-22T04:29:56.662798",
     "exception": false,
     "start_time": "2021-11-22T04:29:56.651480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Reading in the data using pandas. We will tokenize the text later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b22eea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T04:29:56.691261Z",
     "iopub.status.busy": "2021-11-22T04:29:56.690619Z",
     "iopub.status.idle": "2021-11-22T04:29:56.774792Z",
     "shell.execute_reply": "2021-11-22T04:29:56.775225Z",
     "shell.execute_reply.started": "2021-11-22T04:24:01.336649Z"
    },
    "papermill": {
     "duration": 0.101272,
     "end_time": "2021-11-22T04:29:56.775385",
     "exception": false,
     "start_time": "2021-11-22T04:29:56.674113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 1: Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
      "Tweet 2: Forest fire near La Ronge Sask. Canada\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10876 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "3258  10861     NaN      NaN   \n",
       "3259  10865     NaN      NaN   \n",
       "3260  10868     NaN      NaN   \n",
       "3261  10874     NaN      NaN   \n",
       "3262  10875     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...       0  \n",
       "3259  Storm in RI worse than last hurricane. My city...       1  \n",
       "3260  Green Line derailment in Chicago http://t.co/U...       1  \n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...       1  \n",
       "3262  #CityofCalgary has activated its Municipal Eme...       1  \n",
       "\n",
       "[10876 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading input data with pandas\n",
    "train = pd.read_csv(os.path.join(TWEETS_DATASET_PATH, \"train.csv\")\n",
    "test = pd.read_csv(os.path.join(TWEETS_DATASET_PATH, \"test.csv\"))\n",
    "# submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\n",
    "\n",
    "if FINAL_TRAIN: # let's get this model into production!\n",
    "    train = pd.concat([train, test], sort=False)\n",
    "\n",
    "#visualizing some of the tweets\n",
    "for i, val in enumerate(train.iloc[:2][\"text\"].to_list()):\n",
    "    print(\"Tweet {}: {}\".format(i+1, val))\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d8829b",
   "metadata": {
    "papermill": {
     "duration": 0.011485,
     "end_time": "2021-11-22T04:29:56.799181",
     "exception": false,
     "start_time": "2021-11-22T04:29:56.787696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <center>bert_encode function</center>\n",
    "\n",
    "\n",
    "### tokenizer\n",
    "We are using the [Tensorflow Research's BERT tokenization method](https://github.com/tensorflow/models/blob/master/official/nlp/bert/tokenization.py). This tokenization method can be thought of as three steps.\n",
    "\n",
    "- Text Normalization\n",
    "    - The first part of the tokenizer converts the text to lowercase (given that we are using the uncased version of roBERTa), converts whitespace to spaces, and strips out accent markers.\n",
    "    ```\n",
    "    \"Alex Pättason's, \"  -> \"alex pattason's,\"\n",
    "    ```\n",
    "    <br></br>\n",
    "- Punctuation splitting\n",
    "    - This next step adds spaces on each side of all \"punctuation\". Note that this includes any non-letter/number/space ASCII characters (ie including \\$, \\@). See more of this in the Docs. \n",
    "    ```\n",
    "    \"Alex Pättason's, \"  -> \"alex pattason ' s ,\"\n",
    "    ```\n",
    "    <br></br>\n",
    "- WordPiece tokenization\n",
    "    - This step applies what is called whitespace tokenization to the output of the process above, and apply's WordPiece tokenization to each word separately. See the example below.\n",
    "    ```\n",
    "    \"Alex Pättason's, \"  -> \"alex pat ##ta ##son ' s ,\"\n",
    "    ```\n",
    "   \n",
    "### tags\n",
    "The next part of the function reduces the length of the text by the max_length that we have specified and adds [CLS] and [SEP] tags to the end of the array. The [CLS] tag is short for classification and indicates the start of the sentence. Similarly, the [SEP] tag indicates the end of the sentence.\n",
    "\n",
    "### convert_tokens_to_ids + pad_masks\n",
    "\n",
    "We then use the tokenizer method to replace the string representation of words with integers. We also create the input mask (AKA pad_masks), and the segment id's. Note that we are not fulfilling the segment_ids full benefits below as we are only passing an array of zeros. More on the tokens, pad_masks, and segment_ids further in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c62534",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T04:29:56.830581Z",
     "iopub.status.busy": "2021-11-22T04:29:56.829725Z",
     "iopub.status.idle": "2021-11-22T04:29:56.832283Z",
     "shell.execute_reply": "2021-11-22T04:29:56.831770Z",
     "shell.execute_reply.started": "2021-11-22T04:24:01.555943Z"
    },
    "papermill": {
     "duration": 0.021225,
     "end_time": "2021-11-22T04:29:56.832422",
     "exception": false,
     "start_time": "2021-11-22T04:29:56.811197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "            \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379f98c8",
   "metadata": {
    "papermill": {
     "duration": 0.011398,
     "end_time": "2021-11-22T04:29:56.855774",
     "exception": false,
     "start_time": "2021-11-22T04:29:56.844376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <center>build_model function</center>\n",
    "\n",
    "The first three components of the function are basically preprocessing plain text inputs into the input format expected by the roBERTa model.\n",
    "\n",
    "### input_word_ids\n",
    "- Basically maps each word to its token id. There can be multiple different values that correspond with the same word. For example, \"smell\" could be encoded both as 883 and 789.\n",
    "<br></br>\n",
    "```\n",
    "text = \"I love this notebook. It is Great.\"\n",
    "input_word_ids = [10, 235, 123, 938, 184, 301, 567]\n",
    "```\n",
    "\n",
    "### the input_mask\n",
    "- Shows where the sentence begins, and where it ends using an array. All input tokens that are not padding are given a value of 1, and all values that are padding are given 0. If the sentence exceeds that max_length, then the entire vector will be of 1's.\n",
    "<br></br>\n",
    "```\n",
    "text = \"I love this notebook. It is Great.\"\n",
    "input_mask = [1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
    "```\n",
    "\n",
    "### segment_ids\n",
    "- This component is still a little vague for me, but from my understanding, it is recognizing segments of the text. The start of each segment has a 1 in the array, and other components and padding all have a zero. I am unsure as to whether this corresponds to the end of sentences or paragraphs, but if you can explain this better please do so in the comments below!\n",
    "<br></br>\n",
    "```\n",
    "text = \"I love this notebook. It is Great.\"\n",
    "segment_ids = [1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af3bed7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T04:29:56.886498Z",
     "iopub.status.busy": "2021-11-22T04:29:56.885627Z",
     "iopub.status.idle": "2021-11-22T04:29:56.888189Z",
     "shell.execute_reply": "2021-11-22T04:29:56.887686Z",
     "shell.execute_reply.started": "2021-11-22T04:24:01.565584Z"
    },
    "papermill": {
     "duration": 0.02073,
     "end_time": "2021-11-22T04:29:56.888304",
     "exception": false,
     "start_time": "2021-11-22T04:29:56.867574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(bert_layer, max_len=512):\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "    #could be pooled_output, sequence_output yet sequence output provides for each input token (in context)\n",
    "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    hidden = clf_output\n",
    "    for h in N_HIDDEN_UNITS.split(\",\"):\n",
    "        hidden = Dense(int(h), activation='relu', kernel_regularizer=regularizers.l2(L2_LOSS_CONST))(hidden)\n",
    "    out = Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(L2_LOSS_CONST))(hidden)\n",
    "    \n",
    "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "    \n",
    "    #specifying optimizer\n",
    "    model.compile(Adam(learning_rate=LEARNING_RATE, ), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1802b097",
   "metadata": {
    "papermill": {
     "duration": 0.011491,
     "end_time": "2021-11-22T04:29:56.911724",
     "exception": false,
     "start_time": "2021-11-22T04:29:56.900233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Build Model + Preprocess Data\n",
    "\n",
    "The first cell below is basically loading in the version of the roBERTa model that we want to use. We are using a Large uncased model. The most simple way to use a roBERTa model and modify it to a specific use case is to set it as a KerasLayer.\n",
    "\n",
    "Note there are many different variations of BERT models that you can look through here --> [TFhub Bert](https://tfhub.dev/google/collections/bert/1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6220917",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T04:29:56.939462Z",
     "iopub.status.busy": "2021-11-22T04:29:56.938903Z",
     "iopub.status.idle": "2021-11-22T04:30:27.530773Z",
     "shell.execute_reply": "2021-11-22T04:30:27.530252Z",
     "shell.execute_reply.started": "2021-11-22T04:24:01.577209Z"
    },
    "papermill": {
     "duration": 30.607201,
     "end_time": "2021-11-22T04:30:27.530910",
     "exception": false,
     "start_time": "2021-11-22T04:29:56.923709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 03:02:19.959003: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-10 03:02:20.052590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:86:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-12-10 03:02:20.052629: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n",
      "2021-12-10 03:02:20.060707: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-10 03:02:20.063324: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-10 03:02:20.063931: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-10 03:02:20.072051: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-10 03:02:20.073536: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-10 03:02:20.087483: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-10 03:02:20.089669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2021-12-10 03:02:20.094222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:86:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-12-10 03:02:20.095905: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n",
      "2021-12-10 03:02:20.095941: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-10 03:02:20.095954: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-10 03:02:20.095966: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-10 03:02:20.095978: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-10 03:02:20.095989: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-10 03:02:20.096001: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-10 03:02:20.098093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2021-12-10 03:02:20.098122: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n",
      "2021-12-10 03:02:21.138650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-10 03:02:21.138683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2021-12-10 03:02:21.138689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2021-12-10 03:02:21.143267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30158 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "#load uncased bert model\n",
    "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
    "bert_layer = hub.KerasLayer(module_url, trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826726bd",
   "metadata": {
    "papermill": {
     "duration": 0.011998,
     "end_time": "2021-11-22T04:30:27.555635",
     "exception": false,
     "start_time": "2021-11-22T04:30:27.543637",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the next cell, we are setting up the tokenizer that will be used to preprocess our input data to what BERT understands. We have to specify a vocab file so that the tokenizer knows what number to encode each word as then we have to specify whether we want uncased or cased text. We will use the same vocab_file that the pre-trained model was trained on (Google's SentencePiece in this case) and we will also use the same case that the model was built for (uncased).\n",
    "\n",
    "Finally, once we have these two variables, we create the tokenizer and tokenize the training and testing data using the bert_encode function that we created above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4deaafe2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T04:30:27.585588Z",
     "iopub.status.busy": "2021-11-22T04:30:27.584813Z",
     "iopub.status.idle": "2021-11-22T04:30:33.945048Z",
     "shell.execute_reply": "2021-11-22T04:30:33.944089Z",
     "shell.execute_reply.started": "2021-11-22T04:24:32.799539Z"
    },
    "papermill": {
     "duration": 6.377541,
     "end_time": "2021-11-22T04:30:33.945195",
     "exception": false,
     "start_time": "2021-11-22T04:30:27.567654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#vocab file from pre-trained BERT for tokenization\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "\n",
    "#returns true/false depending on if we selected cased/uncased bert layer\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "\n",
    "#Create the tokenizer\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "\n",
    "#tokenizing the training and testing data\n",
    "train_input = bert_encode(train.text.values, tokenizer, max_len=MAX_LEN)\n",
    "test_input = bert_encode(test.text.values, tokenizer, max_len=MAX_LEN)\n",
    "train_labels = train.target.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dd99e7",
   "metadata": {
    "papermill": {
     "duration": 0.011642,
     "end_time": "2021-11-22T04:30:33.969249",
     "exception": false,
     "start_time": "2021-11-22T04:30:33.957607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Having a look at the model summary. We can see the three input layers that we created followed by the roBERTa model which is in the keras_layer. We have the final dense layer which predicts the sentiment of the tweet on a scale of 0-1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbd59b9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T04:30:34.002960Z",
     "iopub.status.busy": "2021-11-22T04:30:33.998627Z",
     "iopub.status.idle": "2021-11-22T04:30:35.189520Z",
     "shell.execute_reply": "2021-11-22T04:30:35.189015Z",
     "shell.execute_reply.started": "2021-11-22T04:24:39.375999Z"
    },
    "papermill": {
     "duration": 1.208638,
     "end_time": "2021-11-22T04:30:35.189647",
     "exception": false,
     "start_time": "2021-11-22T04:30:33.981009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x2aec534947d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x2aec534947d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x2aec534947d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 1024), (None 335141889   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 1024)]       0           keras_layer[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         1049600     tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          524800      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          131328      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            257         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 336,847,874\n",
      "Trainable params: 336,847,873\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(bert_layer, max_len=MAX_LEN)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26452300",
   "metadata": {
    "papermill": {
     "duration": 0.011962,
     "end_time": "2021-11-22T04:30:35.213836",
     "exception": false,
     "start_time": "2021-11-22T04:30:35.201874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Model\n",
    "\n",
    "The next cell is a simple way of training the model using Keras. We have included the built-in ModelCheckpoint callback to only save the model that has the highest validation loss. This ensures we are only saving the best models. \n",
    "\n",
    "\n",
    "We could decrease the randomness of the split by doing some sort of a stratified split, or cross-validation, but this will do for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "843fd828",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T04:30:35.243607Z",
     "iopub.status.busy": "2021-11-22T04:30:35.242700Z",
     "iopub.status.idle": "2021-11-22T04:52:27.580878Z",
     "shell.execute_reply": "2021-11-22T04:52:27.580276Z",
     "shell.execute_reply.started": "2021-11-22T04:24:40.757232Z"
    },
    "papermill": {
     "duration": 1312.355107,
     "end_time": "2021-11-22T04:52:27.581025",
     "exception": false,
     "start_time": "2021-11-22T04:30:35.225918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 03:05:13.424386: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1224/1224 [==============================] - ETA: 0s - loss: 6.3078 - accuracy: 0.8194WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0528s vs `on_test_batch_end` time: 0.1376s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0528s vs `on_test_batch_end` time: 0.1376s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1224/1224 [==============================] - 726s 593ms/step - loss: 6.3078 - accuracy: 0.8194 - val_loss: 6.0409 - val_accuracy: 0.8281\n",
      "Epoch 2/100\n",
      "1224/1224 [==============================] - 720s 588ms/step - loss: 5.7728 - accuracy: 0.8633 - val_loss: 5.5786 - val_accuracy: 0.8502\n",
      "Epoch 3/100\n",
      "1224/1224 [==============================] - 716s 585ms/step - loss: 5.3054 - accuracy: 0.8850 - val_loss: 5.1648 - val_accuracy: 0.8557\n",
      "Epoch 4/100\n",
      "1224/1224 [==============================] - 720s 588ms/step - loss: 4.8383 - accuracy: 0.9082 - val_loss: 4.7575 - val_accuracy: 0.8539\n",
      "Epoch 5/100\n",
      "1224/1224 [==============================] - 720s 588ms/step - loss: 4.4029 - accuracy: 0.9254 - val_loss: 4.4678 - val_accuracy: 0.8300\n",
      "Epoch 6/100\n",
      "1224/1224 [==============================] - 721s 589ms/step - loss: 4.0068 - accuracy: 0.9398 - val_loss: 4.1289 - val_accuracy: 0.8401\n",
      "Epoch 7/100\n",
      "1224/1224 [==============================] - 717s 586ms/step - loss: 3.6226 - accuracy: 0.9549 - val_loss: 3.9581 - val_accuracy: 0.8483\n",
      "Epoch 8/100\n",
      "1224/1224 [==============================] - 720s 588ms/step - loss: 3.2618 - accuracy: 0.9684 - val_loss: 3.6152 - val_accuracy: 0.8336\n",
      "Epoch 9/100\n",
      "1224/1224 [==============================] - 716s 585ms/step - loss: 2.9258 - accuracy: 0.9724 - val_loss: 3.3810 - val_accuracy: 0.8483\n",
      "Epoch 10/100\n",
      "1224/1224 [==============================] - 716s 585ms/step - loss: 2.6063 - accuracy: 0.9772 - val_loss: 3.0413 - val_accuracy: 0.8346\n",
      "Epoch 11/100\n",
      "1224/1224 [==============================] - 721s 589ms/step - loss: 2.3045 - accuracy: 0.9814 - val_loss: 2.7730 - val_accuracy: 0.8336\n",
      "Epoch 12/100\n",
      "1224/1224 [==============================] - 720s 588ms/step - loss: 2.0255 - accuracy: 0.9838 - val_loss: 2.5621 - val_accuracy: 0.8162\n",
      "Epoch 13/100\n",
      "1224/1224 [==============================] - 719s 587ms/step - loss: 1.7691 - accuracy: 0.9855 - val_loss: 2.3743 - val_accuracy: 0.8336\n",
      "Epoch 14/100\n",
      "1224/1224 [==============================] - 717s 586ms/step - loss: 1.5263 - accuracy: 0.9892 - val_loss: 2.1164 - val_accuracy: 0.8364\n",
      "Epoch 15/100\n",
      "1224/1224 [==============================] - 717s 586ms/step - loss: 1.3001 - accuracy: 0.9926 - val_loss: 1.9762 - val_accuracy: 0.8438\n",
      "Epoch 16/100\n",
      "1224/1224 [==============================] - 720s 589ms/step - loss: 1.0889 - accuracy: 0.9915 - val_loss: 1.7152 - val_accuracy: 0.8419\n",
      "Epoch 17/100\n",
      "1224/1224 [==============================] - 720s 588ms/step - loss: 0.9172 - accuracy: 0.9897 - val_loss: 1.5449 - val_accuracy: 0.8364\n",
      "Epoch 18/100\n",
      "1224/1224 [==============================] - 717s 586ms/step - loss: 0.7652 - accuracy: 0.9920 - val_loss: 1.4934 - val_accuracy: 0.8290\n",
      "Epoch 19/100\n",
      "1224/1224 [==============================] - 717s 586ms/step - loss: 0.6414 - accuracy: 0.9909 - val_loss: 1.1922 - val_accuracy: 0.8520\n",
      "Epoch 20/100\n",
      "1224/1224 [==============================] - 707s 578ms/step - loss: 0.5393 - accuracy: 0.9909 - val_loss: 1.2540 - val_accuracy: 0.8346\n",
      "Epoch 21/100\n",
      "1224/1224 [==============================] - 721s 589ms/step - loss: 0.4558 - accuracy: 0.9911 - val_loss: 1.1211 - val_accuracy: 0.8263\n",
      "Epoch 22/100\n",
      "1224/1224 [==============================] - 720s 588ms/step - loss: 0.3808 - accuracy: 0.9918 - val_loss: 0.9301 - val_accuracy: 0.8364\n",
      "Epoch 23/100\n",
      "1224/1224 [==============================] - 710s 580ms/step - loss: 0.3238 - accuracy: 0.9920 - val_loss: 0.9948 - val_accuracy: 0.8438\n",
      "Epoch 24/100\n",
      "1224/1224 [==============================] - 710s 580ms/step - loss: 0.2687 - accuracy: 0.9940 - val_loss: 0.9919 - val_accuracy: 0.8456\n",
      "Epoch 25/100\n",
      "1224/1224 [==============================] - 710s 580ms/step - loss: 0.2270 - accuracy: 0.9942 - val_loss: 0.9645 - val_accuracy: 0.8520\n",
      "Epoch 26/100\n",
      "1224/1224 [==============================] - 710s 580ms/step - loss: 0.1863 - accuracy: 0.9956 - val_loss: 0.9705 - val_accuracy: 0.8502\n",
      "Epoch 27/100\n",
      "1224/1224 [==============================] - 720s 588ms/step - loss: 0.1519 - accuracy: 0.9950 - val_loss: 0.8988 - val_accuracy: 0.8419\n",
      "Epoch 28/100\n",
      "1224/1224 [==============================] - 717s 586ms/step - loss: 0.1405 - accuracy: 0.9901 - val_loss: 0.7867 - val_accuracy: 0.8410\n",
      "Epoch 29/100\n",
      "1224/1224 [==============================] - 710s 580ms/step - loss: 0.1160 - accuracy: 0.9942 - val_loss: 0.9267 - val_accuracy: 0.8373\n",
      "Epoch 30/100\n",
      "1224/1224 [==============================] - 710s 580ms/step - loss: 0.1003 - accuracy: 0.9953 - val_loss: 0.9741 - val_accuracy: 0.8502\n",
      "Epoch 31/100\n",
      "1224/1224 [==============================] - 719s 588ms/step - loss: 0.0981 - accuracy: 0.9925 - val_loss: 0.7240 - val_accuracy: 0.8483\n",
      "Epoch 32/100\n",
      "1224/1224 [==============================] - 710s 580ms/step - loss: 0.0853 - accuracy: 0.9943 - val_loss: 0.7340 - val_accuracy: 0.8502\n",
      "Epoch 33/100\n",
      "1224/1224 [==============================] - 710s 580ms/step - loss: 0.0715 - accuracy: 0.9960 - val_loss: 0.8663 - val_accuracy: 0.8520\n",
      "Epoch 34/100\n",
      "1224/1224 [==============================] - 710s 580ms/step - loss: 0.0651 - accuracy: 0.9955 - val_loss: 0.8716 - val_accuracy: 0.8539\n",
      "Epoch 35/100\n",
      "1224/1224 [==============================] - 710s 580ms/step - loss: 0.0719 - accuracy: 0.9918 - val_loss: 0.8646 - val_accuracy: 0.8447\n",
      "Epoch 36/100\n",
      "1224/1224 [==============================] - 710s 580ms/step - loss: 0.0595 - accuracy: 0.9950 - val_loss: 0.8718 - val_accuracy: 0.8281\n",
      "Epoch 37/100\n",
      "1224/1224 [==============================] - 710s 580ms/step - loss: 0.0551 - accuracy: 0.9945 - val_loss: 0.8664 - val_accuracy: 0.8438\n",
      "Epoch 38/100\n",
      "1224/1224 [==============================] - 711s 581ms/step - loss: 0.0537 - accuracy: 0.9947 - val_loss: 0.7855 - val_accuracy: 0.8465\n",
      "Epoch 39/100\n",
      "1224/1224 [==============================] - 710s 580ms/step - loss: 0.0488 - accuracy: 0.9950 - val_loss: 0.8624 - val_accuracy: 0.8410\n",
      "Epoch 40/100\n",
      "1224/1224 [==============================] - 707s 577ms/step - loss: 0.0422 - accuracy: 0.9957 - val_loss: 0.8940 - val_accuracy: 0.8438\n",
      "Epoch 41/100\n",
      "1224/1224 [==============================] - 711s 581ms/step - loss: 0.0368 - accuracy: 0.9963 - val_loss: 0.9075 - val_accuracy: 0.8309\n",
      "Epoch 42/100\n",
      "1224/1224 [==============================] - 710s 580ms/step - loss: 0.0420 - accuracy: 0.9944 - val_loss: 0.8988 - val_accuracy: 0.8290\n",
      "Epoch 43/100\n",
      "1224/1224 [==============================] - 711s 581ms/step - loss: 0.0424 - accuracy: 0.9938 - val_loss: 0.8030 - val_accuracy: 0.8529\n",
      "Epoch 44/100\n",
      "1224/1224 [==============================] - 710s 580ms/step - loss: 0.0394 - accuracy: 0.9942 - val_loss: 0.7832 - val_accuracy: 0.8465\n",
      "Epoch 45/100\n",
      "1224/1224 [==============================] - 708s 579ms/step - loss: 0.0311 - accuracy: 0.9960 - val_loss: 0.8845 - val_accuracy: 0.8465\n",
      "Epoch 47/100\n",
      "1224/1224 [==============================] - 709s 580ms/step - loss: 0.0302 - accuracy: 0.9962 - val_loss: 0.8606 - val_accuracy: 0.8465\n",
      "Epoch 48/100\n",
      "1224/1224 [==============================] - 707s 577ms/step - loss: 0.0286 - accuracy: 0.9963 - val_loss: 0.8772 - val_accuracy: 0.8465\n",
      "Epoch 49/100\n",
      "1224/1224 [==============================] - 707s 577ms/step - loss: 0.0267 - accuracy: 0.9965 - val_loss: 0.9221 - val_accuracy: 0.8511\n",
      "Epoch 50/100\n",
      "1224/1224 [==============================] - 707s 577ms/step - loss: 0.0403 - accuracy: 0.9934 - val_loss: 0.7432 - val_accuracy: 0.8520\n",
      "Epoch 51/100\n",
      "1224/1224 [==============================] - 706s 577ms/step - loss: 0.0286 - accuracy: 0.9961 - val_loss: 0.8380 - val_accuracy: 0.8465\n",
      "Epoch 52/100\n",
      "1224/1224 [==============================] - 707s 578ms/step - loss: 0.0264 - accuracy: 0.9963 - val_loss: 0.8404 - val_accuracy: 0.8529\n",
      "Epoch 53/100\n",
      "1224/1224 [==============================] - 706s 577ms/step - loss: 0.0253 - accuracy: 0.9964 - val_loss: 0.9032 - val_accuracy: 0.8493\n",
      "Epoch 54/100\n",
      "1224/1224 [==============================] - 708s 578ms/step - loss: 0.0250 - accuracy: 0.9964 - val_loss: 0.8703 - val_accuracy: 0.8447\n",
      "Epoch 55/100\n",
      "1224/1224 [==============================] - 707s 578ms/step - loss: 0.0237 - accuracy: 0.9962 - val_loss: 0.9662 - val_accuracy: 0.8419\n",
      "Epoch 56/100\n",
      "1224/1224 [==============================] - 708s 578ms/step - loss: 0.0229 - accuracy: 0.9964 - val_loss: 0.9586 - val_accuracy: 0.8493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "1224/1224 [==============================] - 717s 586ms/step - loss: 0.0339 - accuracy: 0.9940 - val_loss: 0.7221 - val_accuracy: 0.8309\n",
      "Epoch 58/100\n",
      "1224/1224 [==============================] - 711s 581ms/step - loss: 0.0317 - accuracy: 0.9942 - val_loss: 0.7979 - val_accuracy: 0.8290\n",
      "Epoch 59/100\n",
      "1224/1224 [==============================] - 710s 580ms/step - loss: 0.0253 - accuracy: 0.9962 - val_loss: 0.9167 - val_accuracy: 0.8346\n",
      "Epoch 60/100\n",
      "1224/1224 [==============================] - 706s 577ms/step - loss: 0.0243 - accuracy: 0.9961 - val_loss: 0.9400 - val_accuracy: 0.8382\n",
      "Epoch 62/100\n",
      "1224/1224 [==============================] - 709s 579ms/step - loss: 0.0267 - accuracy: 0.9953 - val_loss: 0.9490 - val_accuracy: 0.8134\n",
      "Epoch 63/100\n",
      "1224/1224 [==============================] - 706s 577ms/step - loss: 0.0317 - accuracy: 0.9942 - val_loss: 0.8682 - val_accuracy: 0.8290\n",
      "Epoch 64/100\n",
      "1224/1224 [==============================] - 706s 577ms/step - loss: 0.0332 - accuracy: 0.9922 - val_loss: 0.8481 - val_accuracy: 0.8254\n",
      "Epoch 65/100\n",
      "1224/1224 [==============================] - 708s 578ms/step - loss: 0.0240 - accuracy: 0.9949 - val_loss: 0.8687 - val_accuracy: 0.8263\n",
      "Epoch 66/100\n",
      "1224/1224 [==============================] - 708s 578ms/step - loss: 0.0210 - accuracy: 0.9960 - val_loss: 0.9889 - val_accuracy: 0.8281\n",
      "Epoch 67/100\n",
      "1224/1224 [==============================] - 709s 580ms/step - loss: 0.0204 - accuracy: 0.9964 - val_loss: 1.0259 - val_accuracy: 0.8290\n",
      "Epoch 68/100\n",
      "1224/1224 [==============================] - 710s 580ms/step - loss: 0.0203 - accuracy: 0.9964 - val_loss: 1.0317 - val_accuracy: 0.8300\n",
      "Epoch 69/100\n",
      "1224/1224 [==============================] - 708s 579ms/step - loss: 0.0201 - accuracy: 0.9964 - val_loss: 1.0410 - val_accuracy: 0.8318\n",
      "Epoch 70/100\n",
      "1224/1224 [==============================] - 709s 579ms/step - loss: 0.0200 - accuracy: 0.9965 - val_loss: 1.0281 - val_accuracy: 0.8318\n",
      "Epoch 71/100\n",
      "1224/1224 [==============================] - 707s 577ms/step - loss: 0.0344 - accuracy: 0.9927 - val_loss: 0.7588 - val_accuracy: 0.8520\n",
      "Epoch 72/100\n",
      "1224/1224 [==============================] - 706s 577ms/step - loss: 0.0271 - accuracy: 0.9951 - val_loss: 0.8951 - val_accuracy: 0.8355\n",
      "Epoch 73/100\n",
      "1224/1224 [==============================] - 709s 579ms/step - loss: 0.0253 - accuracy: 0.9952 - val_loss: 0.8822 - val_accuracy: 0.8300\n",
      "Epoch 74/100\n",
      "1224/1224 [==============================] - 706s 577ms/step - loss: 0.0234 - accuracy: 0.9955 - val_loss: 0.8898 - val_accuracy: 0.8309\n",
      "Epoch 75/100\n",
      "1224/1224 [==============================] - 719s 587ms/step - loss: 0.0366 - accuracy: 0.9924 - val_loss: 0.6844 - val_accuracy: 0.8447\n",
      "Epoch 76/100\n",
      "1224/1224 [==============================] - 709s 579ms/step - loss: 0.0243 - accuracy: 0.9956 - val_loss: 0.7933 - val_accuracy: 0.8410\n",
      "Epoch 77/100\n",
      "1224/1224 [==============================] - 707s 578ms/step - loss: 0.0221 - accuracy: 0.9963 - val_loss: 0.8555 - val_accuracy: 0.8336\n",
      "Epoch 78/100\n",
      "1224/1224 [==============================] - 709s 579ms/step - loss: 0.0215 - accuracy: 0.9955 - val_loss: 0.8952 - val_accuracy: 0.8392\n",
      "Epoch 79/100\n",
      "1224/1224 [==============================] - 708s 578ms/step - loss: 0.0223 - accuracy: 0.9960 - val_loss: 0.8617 - val_accuracy: 0.8355\n",
      "Epoch 80/100\n",
      "1224/1224 [==============================] - 705s 576ms/step - loss: 0.0216 - accuracy: 0.9961 - val_loss: 0.9040 - val_accuracy: 0.8364\n",
      "Epoch 81/100\n",
      "1224/1224 [==============================] - 700s 572ms/step - loss: 0.0209 - accuracy: 0.9962 - val_loss: 0.9426 - val_accuracy: 0.8382\n",
      "Epoch 82/100\n",
      "1224/1224 [==============================] - 699s 571ms/step - loss: 0.0220 - accuracy: 0.9956 - val_loss: 0.9305 - val_accuracy: 0.8364\n",
      "Epoch 83/100\n",
      "1224/1224 [==============================] - 698s 571ms/step - loss: 0.0386 - accuracy: 0.9922 - val_loss: 0.6908 - val_accuracy: 0.8392\n",
      "Epoch 84/100\n",
      "1224/1224 [==============================] - 698s 571ms/step - loss: 0.0275 - accuracy: 0.9947 - val_loss: 0.8058 - val_accuracy: 0.8382\n",
      "Epoch 85/100\n",
      "1224/1224 [==============================] - 698s 571ms/step - loss: 0.0230 - accuracy: 0.9956 - val_loss: 0.8150 - val_accuracy: 0.8502\n",
      "Epoch 86/100\n",
      "1224/1224 [==============================] - 698s 571ms/step - loss: 0.0218 - accuracy: 0.9960 - val_loss: 0.8494 - val_accuracy: 0.8428\n",
      "Epoch 87/100\n",
      "1224/1224 [==============================] - 698s 571ms/step - loss: 0.0222 - accuracy: 0.9957 - val_loss: 0.8091 - val_accuracy: 0.8355\n",
      "Epoch 88/100\n",
      "1224/1224 [==============================] - 698s 571ms/step - loss: 0.0206 - accuracy: 0.9960 - val_loss: 0.8456 - val_accuracy: 0.8272\n",
      "Epoch 89/100\n",
      "1224/1224 [==============================] - 698s 570ms/step - loss: 0.0208 - accuracy: 0.9961 - val_loss: 0.8373 - val_accuracy: 0.8493\n",
      "Epoch 90/100\n",
      "1224/1224 [==============================] - 698s 570ms/step - loss: 0.0229 - accuracy: 0.9958 - val_loss: 0.9053 - val_accuracy: 0.8327\n",
      "Epoch 91/100\n",
      "1224/1224 [==============================] - 698s 571ms/step - loss: 0.0283 - accuracy: 0.9941 - val_loss: 0.8180 - val_accuracy: 0.8281\n",
      "Epoch 92/100\n",
      "1224/1224 [==============================] - 698s 571ms/step - loss: 0.0230 - accuracy: 0.9950 - val_loss: 0.7864 - val_accuracy: 0.8493\n",
      "Epoch 93/100\n",
      "1224/1224 [==============================] - 698s 570ms/step - loss: 0.0203 - accuracy: 0.9964 - val_loss: 0.7657 - val_accuracy: 0.8502\n",
      "Epoch 94/100\n",
      "1224/1224 [==============================] - 698s 571ms/step - loss: 0.0195 - accuracy: 0.9960 - val_loss: 0.8640 - val_accuracy: 0.8364\n",
      "Epoch 95/100\n",
      "1224/1224 [==============================] - 698s 571ms/step - loss: 0.0194 - accuracy: 0.9963 - val_loss: 0.8710 - val_accuracy: 0.8364\n",
      "Epoch 96/100\n",
      "1224/1224 [==============================] - 698s 571ms/step - loss: 0.0198 - accuracy: 0.9963 - val_loss: 0.9097 - val_accuracy: 0.8373\n",
      "Epoch 97/100\n",
      "1224/1224 [==============================] - 698s 571ms/step - loss: 0.0241 - accuracy: 0.9952 - val_loss: 0.9766 - val_accuracy: 0.8318\n",
      "Epoch 98/100\n",
      "1224/1224 [==============================] - 698s 570ms/step - loss: 0.0323 - accuracy: 0.9931 - val_loss: 0.7375 - val_accuracy: 0.8318\n",
      "Epoch 99/100\n",
      "1224/1224 [==============================] - 698s 571ms/step - loss: 0.0239 - accuracy: 0.9950 - val_loss: 0.8279 - val_accuracy: 0.8281\n",
      "Epoch 100/100\n",
      "1224/1224 [==============================] - 698s 570ms/step - loss: 0.0205 - accuracy: 0.9963 - val_loss: 0.8639 - val_accuracy: 0.8318\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(MODEL_CHECKPOINT_NAME, monitor='val_loss', save_best_only=True)\n",
    "\n",
    "train_history = model.fit(\n",
    "    train_input, train_labels,\n",
    "    validation_split=0.1,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint],\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b2937d",
   "metadata": {
    "papermill": {
     "duration": 0.340167,
     "end_time": "2021-11-22T04:52:28.260516",
     "exception": false,
     "start_time": "2021-11-22T04:52:27.920349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Make Prediction\n",
    "\n",
    "Using the model to make predictions on the testing set. We round the prediction to 1 or 0. 1 is a disaster tweet, and 0 is a regular tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e942184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_true, y_predicted, log_filename=None):\n",
    "    acc = metrics.accuracy_score(y_true, y_predicted)\n",
    "    precision, recall, f1, support = metrics.precision_recall_fscore_support(y_true, y_predicted)\n",
    "    cf = metrics.confusion_matrix(y_true, y_predicted)\n",
    "    \n",
    "    lines = []\n",
    "    lines += [f\"Accuracy: {acc}\"]\n",
    "    lines += [f\"Precision: {precision}\"]\n",
    "    lines += [f\"Recall: {recall}\"]\n",
    "    lines += [f\"F1: {f1}\"]\n",
    "    lines += [f\"support: {support}\"]\n",
    "    lines += [f\"{cf}\"]\n",
    "    \n",
    "    for line in lines:\n",
    "        print(line)\n",
    "    \n",
    "    if log_filename is not None:\n",
    "        with open(log_filename, \"a\") as lf:\n",
    "                for line in lines:\n",
    "                    lf.write(line)\n",
    "                    lf.write(\"\\n\")\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd16ceb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-22T04:52:28.952975Z",
     "iopub.status.busy": "2021-11-22T04:52:28.951827Z",
     "iopub.status.idle": "2021-11-22T04:53:53.592017Z",
     "shell.execute_reply": "2021-11-22T04:53:53.591506Z",
     "shell.execute_reply.started": "2021-11-22T04:24:50.128319Z"
    },
    "papermill": {
     "duration": 84.990807,
     "end_time": "2021-11-22T04:53:53.592153",
     "exception": false,
     "start_time": "2021-11-22T04:52:28.601346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not FINAL_TRAIN:\n",
    "    print(\"Overfitted model test results:\")\n",
    "    test_pred = model.predict(test_input)\n",
    "    print_metrics(test.target, test_pred.round().astype(int).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "729a9da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FINAL_TRAIN:\n",
    "    print(\"Best checkpoint test results (best according to validation loss):\")\n",
    "    best_model = load_model(MODEL_CHECKPOINT_NAME, custom_objects={'KerasLayer': hub.KerasLayer})\n",
    "    test_pred = best_model.predict(test_input)\n",
    "\n",
    "    submission = test[[\"id\"]].copy()\n",
    "    submission[\"target\"] = test_pred.round().astype(int)\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "    print(MODEL_CHECKPOINT_NAME)\n",
    "    print_metrics(test.target, submission.target, f\"{MODEL_CHECKPOINT_NAME}.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f0ee09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready for production! Find the best weights in:\n",
      "model_lr=5e-06_hid=1024,512,256_maxlen=300_batch=8_epochs=100_seed=72_l2=0.003.h5\n"
     ]
    }
   ],
   "source": [
    "if FINAL_TRAIN:\n",
    "    print(f\"Model ready for production! Find the best weights in:\\n{MODEL_CHECKPOINT_NAME}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1453.947289,
   "end_time": "2021-11-22T04:53:57.168348",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-22T04:29:43.221059",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}